{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://scikit-learn.org/stable/_images/grid_search_workflow.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from keras.utils import np_utils\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from skorch import NeuralNetClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import configurations (file paths, etc.)\n",
    "import yaml\n",
    "try:\n",
    "    from yaml import CLoader as Loader, CDumper as Dumper\n",
    "except ImportError:\n",
    "    from yaml import Loader, Dumper\n",
    "    \n",
    "configFile = '../cluster/data/medinfmk/ddi/config/config.yml'\n",
    "\n",
    "with open(configFile, 'r') as ymlfile:\n",
    "    cfg = yaml.load(ymlfile, Loader=Loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathInput = cfg['filePaths']['dirRaw']\n",
    "pathOutput = cfg['filePaths']['dirProcessed']\n",
    "# path to store python binary files (pickles)\n",
    "# in order not to recalculate them every time\n",
    "pathPickles = cfg['filePaths']['dirProcessedFiles']['dirPickles']\n",
    "datasetDirs = cfg['filePaths']['dirRawDatasets']\n",
    "DS1_path = str(datasetDirs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(input_fea, input_lab, seperate=False):\n",
    "    offside_sim_path = input_fea\n",
    "    drug_interaction_matrix_path = input_lab\n",
    "    drug_fea = np.loadtxt(offside_sim_path,dtype=float,delimiter=\",\")\n",
    "    interaction = np.loadtxt(drug_interaction_matrix_path,dtype=int,delimiter=\",\")\n",
    "    train = []\n",
    "    label = []\n",
    "    tmp_fea=[]\n",
    "    drug_fea_tmp = []\n",
    "    for i in range(0, interaction.shape[0]):\n",
    "        for j in range(0, interaction.shape[1]):\n",
    "            label.append(interaction[i,j])\n",
    "            drug_fea_tmp = list(drug_fea[i])\n",
    "            if seperate:\n",
    "        \n",
    "                 tmp_fea = (drug_fea_tmp,drug_fea_tmp)\n",
    "\n",
    "            else:\n",
    "                 tmp_fea = drug_fea_tmp + drug_fea_tmp\n",
    "            train.append(tmp_fea)\n",
    "\n",
    "    return np.array(train), np.array(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transfer_array_format(data):\n",
    "    formated_matrix1 = []\n",
    "    formated_matrix2 = []\n",
    "    for val in data:\n",
    "        formated_matrix1.append(val[0])\n",
    "        formated_matrix2.append(val[1])\n",
    "    return np.array(formated_matrix1), np.array(formated_matrix2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_labels(labels, encoder=None, categorical=True):\n",
    "    if not encoder:\n",
    "        encoder = LabelEncoder()\n",
    "        encoder.fit(labels)\n",
    "        y = encoder.transform(labels).astype(np.int32)\n",
    "    if categorical:\n",
    "        y = np_utils.to_categorical(y)\n",
    "        print(y)\n",
    "    return y, encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_names(labels, encoder=None, categorical=True):\n",
    "    if not encoder:\n",
    "        encoder = LabelEncoder()\n",
    "        encoder.fit(labels)\n",
    "    if categorical:\n",
    "        labels = np_utils.to_categorical(labels)\n",
    "    return labels, encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_fea = pathInput+DS1_path+\"/offsideeffect_Jacarrd_sim.csv\"\n",
    "#input_fea = pathOutput+\"/finalsimddd.txt\"\n",
    "input_lab = pathInput+DS1_path+\"/drug_drug_matrix.csv\"\n",
    "X, y = prepare_data(input_fea, input_lab, seperate = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data1, X_data2 = transfer_array_format(X)\n",
    "X = np.concatenate((X_data1, X_data2), axis = 1)\n",
    "model_input_dim = X.shape[1]\n",
    "#Y, encoder = preprocess_labels(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X, y = make_classification(1500, 1000, n_informative=10, random_state=0)\n",
    "#X = X.astype(np.float32)\n",
    "#y = y.astype(np.int64)\n",
    "\n",
    "tX = torch.from_numpy(X).type(torch.float32)\n",
    "ty = torch.from_numpy(y).type(torch.int64)\n",
    "\n",
    "dataSet = TensorDataset(tX, ty)\n",
    "dataLoader = DataLoader(dataSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NDD(nn.Module):\n",
    "    def __init__(self, D_in=model_input_dim, H1=500, H2=300, D_out=2, drop=0.5):\n",
    "        super(NDD, self).__init__()\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(D_in, H1) # Fully Connected\n",
    "        self.fc2 = nn.Linear(H1, H2)\n",
    "        self.fc3 = nn.Linear(H2, D_out)\n",
    "        self.drop = nn.Dropout(drop)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.drop(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.drop(x)\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NDD(\n",
       "  (fc1): Linear(in_features=1096, out_features=400, bias=True)\n",
       "  (fc2): Linear(in_features=400, out_features=300, bias=True)\n",
       "  (fc3): Linear(in_features=300, out_features=2, bias=True)\n",
       "  (drop): Dropout(p=0.5, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Params\n",
    "\n",
    "# Model\n",
    "D_in, H1, H2, D_out, drop = model_input_dim, 400, 300, 2, 0.5\n",
    "# Training\n",
    "#batch_size, epochs = 100, 20\n",
    "#print_iter = int(epochs / 10)\n",
    "# SGD\n",
    "#learning_rate, momentum, weight_decay, nesterov = 0.01, 0.9, 1e-6, True\n",
    "\n",
    "# Construct our model by instantiating the class defined above\n",
    "model = NDD(D_in, H1, H2, D_out, drop)\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "  print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "  # dim = 0 [30, xxx] -> [10, ...], [10, ...], [10, ...] on 3 GPUs\n",
    "  model = nn.DataParallel(model)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = NeuralNetClassifier(\n",
    "    model,\n",
    "    criterion=nn.CrossEntropyLoss,\n",
    "    #max_epochs=10,\n",
    "    #lr=0.1,\n",
    "    # Shuffle training data on each epoch\n",
    "    iterator_train__shuffle=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipe = Pipeline([\n",
    "#     ('net', net),\n",
    "# ])\n",
    "\n",
    "# pipe.fit(X, y)\n",
    "# y_proba = pipe.predict_proba(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Re-initializing module because the following parameters were re-set: H1, H2.\n",
      "Re-initializing module because the following parameters were re-set: H1, H2.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.5823\u001b[0m       \u001b[32m0.6764\u001b[0m        \u001b[35m0.6532\u001b[0m  7.6535\n",
      "      2        \u001b[36m0.5538\u001b[0m       0.6764        0.6889  11.0068\n",
      "      3        \u001b[36m0.5425\u001b[0m       0.6764        0.7414  8.0967\n",
      "      4        \u001b[36m0.5346\u001b[0m       0.6764        0.8426  9.6943\n",
      "      5        \u001b[36m0.5289\u001b[0m       0.6764        0.8154  9.4526\n",
      "Re-initializing module because the following parameters were re-set: H1, H2.\n",
      "Re-initializing module because the following parameters were re-set: H1, H2.\n",
      "  epoch    train_loss    valid_acc    valid_loss      dur\n",
      "-------  ------------  -----------  ------------  -------\n",
      "      1        \u001b[36m0.5751\u001b[0m       \u001b[32m0.6151\u001b[0m        \u001b[35m0.6680\u001b[0m  23.0491\n",
      "      2        \u001b[36m0.5349\u001b[0m       \u001b[32m0.6764\u001b[0m        \u001b[35m0.5993\u001b[0m  22.6251\n",
      "      3        \u001b[36m0.5178\u001b[0m       0.6764        0.6113  21.0630\n",
      "      4        \u001b[36m0.5054\u001b[0m       \u001b[32m0.7000\u001b[0m        0.5998  7.7773\n",
      "      5        \u001b[36m0.4982\u001b[0m       0.6446        0.6250  5.6340\n",
      "Re-initializing module because the following parameters were re-set: H1, H2.\n",
      "Re-initializing module because the following parameters were re-set: H1, H2.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.5791\u001b[0m       \u001b[32m0.5821\u001b[0m        \u001b[35m0.6508\u001b[0m  9.6957\n",
      "      2        \u001b[36m0.5522\u001b[0m       \u001b[32m0.6847\u001b[0m        \u001b[35m0.5933\u001b[0m  16.4284\n",
      "      3        \u001b[36m0.5363\u001b[0m       \u001b[32m0.6939\u001b[0m        0.5974  10.7786\n",
      "      4        \u001b[36m0.5230\u001b[0m       0.6764        0.6269  14.4990\n",
      "      5        \u001b[36m0.5161\u001b[0m       0.4375        0.8094  6.9920\n",
      "Re-initializing module because the following parameters were re-set: H1, H2.\n",
      "Re-initializing module because the following parameters were re-set: H1, H2.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.5830\u001b[0m       \u001b[32m0.6764\u001b[0m        \u001b[35m0.5998\u001b[0m  6.0022\n",
      "      2        \u001b[36m0.5558\u001b[0m       0.6764        0.6115  20.6626\n",
      "      3        \u001b[36m0.5440\u001b[0m       0.6764        0.6568  9.9753\n",
      "      4        \u001b[36m0.5369\u001b[0m       0.6764        0.8158  22.8361\n",
      "      5        \u001b[36m0.5298\u001b[0m       0.6648        0.7036  9.9977\n",
      "Re-initializing module because the following parameters were re-set: H1, H2.\n",
      "Re-initializing module because the following parameters were re-set: H1, H2.\n",
      "  epoch    train_loss    valid_acc    valid_loss      dur\n",
      "-------  ------------  -----------  ------------  -------\n",
      "      1        \u001b[36m0.5757\u001b[0m       \u001b[32m0.6877\u001b[0m        \u001b[35m0.6284\u001b[0m  18.9291\n",
      "      2        \u001b[36m0.5357\u001b[0m       0.6529        \u001b[35m0.6244\u001b[0m  22.9404\n",
      "      3        \u001b[36m0.5186\u001b[0m       0.6817        \u001b[35m0.6122\u001b[0m  5.7275\n",
      "      4        \u001b[36m0.5080\u001b[0m       0.6764        0.6349  7.1754\n",
      "      5        \u001b[36m0.4982\u001b[0m       0.6701        \u001b[35m0.6018\u001b[0m  6.7717\n",
      "Re-initializing module because the following parameters were re-set: H1, H2.\n",
      "Re-initializing module because the following parameters were re-set: H1, H2.\n",
      "  epoch    train_loss    valid_acc    valid_loss      dur\n",
      "-------  ------------  -----------  ------------  -------\n",
      "      1        \u001b[36m0.5808\u001b[0m       \u001b[32m0.6741\u001b[0m        \u001b[35m0.6267\u001b[0m  20.7257\n",
      "      2        \u001b[36m0.5535\u001b[0m       0.6271        0.6492  18.2241\n",
      "      3        \u001b[36m0.5371\u001b[0m       \u001b[32m0.6764\u001b[0m        \u001b[35m0.6176\u001b[0m  8.3000\n",
      "      4        \u001b[36m0.5258\u001b[0m       0.4969        0.7167  8.2039\n",
      "      5        \u001b[36m0.5168\u001b[0m       0.6764        \u001b[35m0.6123\u001b[0m  14.5389\n",
      "0.5833621929777825 {'lr': 0.1, 'max_epochs': 5, 'module__H1': 300, 'module__H2': 100}\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'lr': [0.1],\n",
    "    'max_epochs': [5],\n",
    "    'module__H1': [300],\n",
    "    'module__H2': [200, 100],\n",
    "}\n",
    "gs = GridSearchCV(net, params, refit=False, cv=3, scoring='accuracy')\n",
    "\n",
    "gs.fit(X, y)\n",
    "print(gs.best_score_, gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
