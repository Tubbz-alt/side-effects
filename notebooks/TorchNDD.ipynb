{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#from __future__ import print_function, division\n",
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "#from skimage import io, transform\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "#from torchvision import transforms, utils\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import np_utils, generic_utils\n",
    "\n",
    "\n",
    "# Ignore warnings\n",
    "#import warnings\n",
    "#warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#plt.ion()   # interactive mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import configurations (file paths, etc.)\n",
    "import yaml\n",
    "try:\n",
    "    from yaml import CLoader as Loader, CDumper as Dumper\n",
    "except ImportError:\n",
    "    from yaml import Loader, Dumper\n",
    "    \n",
    "configFile = '../cluster/data/medinfmk/ddi/config/config.yml'\n",
    "\n",
    "with open(configFile, 'r') as ymlfile:\n",
    "    cfg = yaml.load(ymlfile, Loader=Loader)\n",
    "    \n",
    "#print(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathInput = cfg['filePaths']['dirRaw']\n",
    "pathOutput = cfg['filePaths']['dirProcessed']\n",
    "# path to store python binary files (pickles)\n",
    "# in order not to recalculate them every time\n",
    "pathPickles = cfg['filePaths']['dirProcessedFiles']['dirPickles']\n",
    "datasetDirs = cfg['filePaths']['dirRawDatasets']\n",
    "DS1_path = str(datasetDirs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#landmarks_frame = pd.read_csv('data/faces/face_landmarks.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NDD Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(input_fea, input_lab, seperate=False):\n",
    "    offside_sim_path = input_fea\n",
    "    drug_interaction_matrix_path = input_lab\n",
    "    drug_fea = np.loadtxt(offside_sim_path,dtype=float,delimiter=\",\")\n",
    "    interaction = np.loadtxt(drug_interaction_matrix_path,dtype=int,delimiter=\",\")\n",
    "    train = []\n",
    "    label = []\n",
    "    tmp_fea=[]\n",
    "    drug_fea_tmp = []\n",
    "    for i in range(0, interaction.shape[0]):\n",
    "        for j in range(0, interaction.shape[1]):\n",
    "            label.append(interaction[i,j])\n",
    "            drug_fea_tmp = list(drug_fea[i])\n",
    "            if seperate:\n",
    "        \n",
    "                 tmp_fea = (drug_fea_tmp,drug_fea_tmp)\n",
    "\n",
    "            else:\n",
    "                 tmp_fea = drug_fea_tmp + drug_fea_tmp\n",
    "            train.append(tmp_fea)\n",
    "\n",
    "    return np.array(train), label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transfer_array_format(data):\n",
    "    formated_matrix1 = []\n",
    "    formated_matrix2 = []\n",
    "    for val in data:\n",
    "        formated_matrix1.append(val[0])\n",
    "        formated_matrix2.append(val[1])\n",
    "    return np.array(formated_matrix1), np.array(formated_matrix2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_labels(labels, encoder=None, categorical=True):\n",
    "    if not encoder:\n",
    "        encoder = LabelEncoder()\n",
    "        encoder.fit(labels)\n",
    "        y = encoder.transform(labels).astype(np.int32)\n",
    "    if categorical:\n",
    "        y = np_utils.to_categorical(y)\n",
    "        print(y)\n",
    "    return y, encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_names(labels, encoder=None, categorical=True):\n",
    "    if not encoder:\n",
    "        encoder = LabelEncoder()\n",
    "        encoder.fit(labels)\n",
    "    if categorical:\n",
    "        labels = np_utils.to_categorical(labels)\n",
    "    return labels, encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def NDD(input_dim): \n",
    "#    model = Sequential()\n",
    "#    model.add(Dense(input_dim=input_dim, output_dim=400,init='glorot_normal'))\n",
    "#    model.add(Activation('relu'))\n",
    "#    model.add(Dropout(0.5))\n",
    "#    model.add(Dense(input_dim=400, output_dim=300,init='glorot_normal'))\n",
    "#    model.add(Activation('relu'))\n",
    "#    model.add(Dropout(0.5))\n",
    "#    model.add(Dense(input_dim=300, output_dim=2,init='glorot_normal'))\n",
    "#    model.add(Activation('sigmoid'))\n",
    "#    sgd = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "#    model.compile(loss='binary_crossentropy', optimizer=sgd)                  \n",
    "#    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class NDD(torch.nn.Module):\n",
    "    def __init__(self, D_in, H1, H2, D_out, drop):\n",
    "        super(NDD, self).__init__()\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(D_in, H1) # Fully Connected\n",
    "        self.fc2 = nn.Linear(H1, H2)\n",
    "        self.fc3 = nn.Linear(H2, D_out)\n",
    "        self.drop = nn.Dropout(drop)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.drop(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.drop(x)\n",
    "        x = torch.sigmoid(self.fc3(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_fea = pathInput+DS1_path+\"/offsideeffect_Jacarrd_sim.csv\"\n",
    "# input_lab = pathInput+DS1_path+\"/drug_drug_matrix.csv\"\n",
    "# X, labels = prepare_data(input_fea, input_lab, seperate = True)\n",
    "\n",
    "# X_data1, X_data2 = transfer_array_format(X)\n",
    "# y, encoder = preprocess_labels(labels)\n",
    "# X = np.concatenate((X_data1, X_data2), axis = 1)\n",
    "# model_input_dim = X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Params\n",
    "\n",
    "# Model\n",
    "D_in, H1, H2, D_out, drop = model_input_dim, 400, 300, 2, 0.5\n",
    "# Training\n",
    "batch_size, epochs = 100, 20\n",
    "print_iter = int(epochs / 10)\n",
    "# SGD\n",
    "learning_rate, momentum, weight_decay, nesterov = 0.01, 0.9, 1e-6, True\n",
    "\n",
    "# Construct our model by instantiating the class defined above\n",
    "model = NDD(D_in, H1, H2, D_out, drop)\n",
    "criterion = torch.nn.BCELoss() # binary crossentropy\n",
    "optimizer = torch.optim.SGD(model.parameters(), \n",
    "                            lr=learning_rate, \n",
    "                            momentum=momentum, \n",
    "                            weight_decay=weight_decay, \n",
    "                            nesterov=nesterov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.5951357483863831\n",
      "3 0.5329524874687195\n",
      "5 0.42416104674339294\n",
      "7 0.31613779067993164\n",
      "9 0.16827653348445892\n",
      "11 0.07982834428548813\n",
      "13 -0.08929590880870819\n",
      "15 -0.20616117119789124\n",
      "17 -0.4190223813056946\n",
      "19 -0.6757856011390686\n"
     ]
    }
   ],
   "source": [
    "# Create random Tensors to hold inputs and outputs\n",
    "x = torch.randn(batch_size, D_in)\n",
    "y = torch.randn(batch_size, D_out)\n",
    "\n",
    "for e in range(epochs):\n",
    "    # Forward pass: Compute predicted y by passing x to the model\n",
    "    y_pred = model(x)\n",
    "\n",
    "    # Compute and print loss\n",
    "    loss = criterion(y_pred, y)\n",
    "    if e % print_iter == (print_iter-1):\n",
    "        print(e, loss.item())\n",
    "\n",
    "    # Zero gradients, perform a backward pass, and update the weights.\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
